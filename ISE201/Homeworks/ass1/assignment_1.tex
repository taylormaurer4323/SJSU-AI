\documentclass[11pt]{article}
% \pagestyle{empty}

\setlength{\oddsidemargin}{-0.25 in}
\setlength{\evensidemargin}{-0.25 in}
\setlength{\topmargin}{-0.9 in}
\setlength{\textwidth}{7.0 in}
\setlength{\textheight}{9.0 in}
\setlength{\headsep}{0.75 in}
\setlength{\parindent}{0.3 in}
\setlength{\parskip}{0.1 in}
\usepackage{epsf}
\usepackage{pseudocode}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{bm}
\DeclarePairedDelimiter{\ceil}{\lceil}{\rceil}
\DeclarePairedDelimiter{\floor}{\lfloor}{\rfloor}
% \usepackage{times}
% \usepackage{mathptm}

\def\O{\mathop{\smash{O}}\nolimits}
\def\o{\mathop{\smash{o}}\nolimits}
\newcommand{\e}{{\rm e}}
\newcommand{\R}{{\bf R}}
\newcommand{\Z}{{\bf Z}}
\newcommand{\norm}[1]{\left\lVert#1\right\rVert}
\begin{document}

\textbf{Taylor Maurer, 10/1/2020, ISE201 HW1}
\begin{enumerate}
\item  \           \\
    

\textbf{1.8} \emph{ Profit and sales vectors. A company sells n different products or items. The n-vector p
gives the profit, in dollars per unit, for each of the n items. (The entries of p are typically
positive, but a few items might have negative entries. These items are called loss leaders,
and are used to increase customer engagement in the hope that the customer will make
other, profitable purchases.) The n-vector s gives the total sales of each of the items, over
some period (such as a month), i.e., si is the total number of units of item i sold. (These
are also typically nonnegative, but negative entries can be used to reflect items that were
purchased in a previous time period and returned in this one.) Express the total profit in
terms of p and s using vector notation.}
\\\textbf{Answer: } The total profit can be expressed as the total profit of the multiplication of the profit per unit vector and the total units sold vector; $\bm{p}^T$$\bm{s}$.\\
\\
\\\textbf{3.11} \emph{Neighboring electronic health records. Let x1, . . . , xN be n-vectors that contain n features
extracted from a set of N electronic health records (EHRs), for a population of N patients.
(The features might involve patient attributes and current and past symptoms, diagnoses,
test results, hospitalizations, procedures, and medications.) Briefly describe in words a
practical use for identifying the 10 nearest neighbors of a given EHR (as measured by
their associated feature vectors), among the other EHRs.}
\\\textbf{Answer:}The first thing to be done is to understand the magnitude of the features within the vectors. This is important as when we're doing a distance approach
we want the magnitudes of the features to be about the same. That way one feature isn't skewing the distance calculated. Then for the given patient, we perform the nearest neighbor approach 10 times using the following equation:
\begin{equation}
\norm{\bm{x} - \bm{z_j}} \le \norm{\bm{x} - \bm{z_i}}
\end{equation}
Where $\bm{x}$ is the given patient record, $\bm{z_j}$ is one of ten nearest vectors to $\bm{x}$ within all patient record n-vectors, and $\bm{z_i}$ are all the other n-vectors representing patient records.\\
\\\textbf{6.5} \emph{Adjacency matrix of reversed graph. Suppose A is the adjacency matrix of a directed
graph (see page 112). The reversed graph is obtained by reversing the directions of all
the edges of the original graph. What is the adjacency matrix of the reversed graph?
(Express your answer in terms of A.)}\\
\\\textbf{Answer:} You can take the transpose of the matrix A. This will flip the directionality of the matrix and thus the directionality of the directed adjacency graph.\\
\\\textbf{6.9} \emph{ Multiple channel marketing campaign. Potential customers are divided into m market segments, which are groups of customers with similar demographics, e.g., college educated women aged 25–29. A company markets its products by purchasing advertising in a set of n channels, i.e., specific TV or radio shows, magazines, web sites, blogs, direct mail, and so on. The ability of each channel to deliver impressions or views by potential customers is characterized by the reach matrix, the m x n matrix R, where Rij is the number of views of customers in segment i for each dollar spent on channel j. (We assume that the total number of views in each market segment is the sum of the views from each channel, and that the views from each channel scale linearly with spending.) The n-vector c will denote the company’s purchases of advertising, in dollars, in the n channels. The m-vector v gives the total number of impressions in the m market segments due to the advertising in all channels. Finally, we introduce the m-vector a, where ai gives the profit in dollars}
\begin{enumerate}
\item \emph{Express the total amount of money the company spends on advertising using vector/matrix notation.}
\\\textbf{Answer:}  Since the $\bm{c}$ vector expresses the company's purchasing of advertising, all we need to do is sum that vector. In matrix notation we could say: $Trace(\boldsymbol{I_{nxn}}\bm{c})$.
\item \emph{ Express v using vector/matrix notation, in terms of the other vectors and matrices.}
\\\textbf{Answer:} The $\bm{v}$ n-vector can be found by multiplying the $\boldsymbol{R}$ matrix by $\bm{c}$, as in $\boldsymbol{R}\bm{c}$. You can do this as R's individual elements are in units of views from segment i per dollars spent on channel n. The other assumption is the views of this element are associated with the channel. Thus when you sum within the matrix multiplication you're getting total views from segment i. 
\item \emph{Express the total profit from all market segments using vector/matrix notation.}\\
\\\textbf{Answer:} You can get total profit by multiplying impressions by profit/impressions, or $\bm{v}$ by $\bm{a}$, with a transpose; $\bm{v}^{T}\bm{a}$.
\item \emph{How would you find the single channel most effective at reaching market segment 3,
in terms of impressions per dollar spent?}
\\\textbf{Answer:} Within the reach matrix, you would go to row 3, and find the maximum value. Whatever column contains the maximum value of row 3 will indicate what channel gets the most views per dollar spent of segment 3.
\item \emph{What does it mean if R35 is very small (compared to other entries of R)?}
\\\textbf{Answer:} It means that a lot of advertising dollars are being spent on channel 5, but not many viewers from segment 3 are really seeing it. Therefore maybe advertising dollars should be re-allocated elsewhere.
\end{enumerate}
\textbf{6.12} \emph{Skew-symmetric matrices. An n x n matrix A is called skew-symmetric if $A^T$ = -A, i.e., its transpose is its negative. (A symmetric matrix satisfies $A^T$ = A)}
\begin{enumerate}
\item \emph{Find all 2 x 2 skew-symmetric matrices.}
\\\textbf{Answer:} All 2x2 skew symmetric matrices are given by the following:
\begin{gather}
\boldsymbol{A} = 
\begin{bmatrix} 0 & x \\ -x & 0
\end{bmatrix}
\end{gather}
And then the following of skew-symmetric matrices are true:
\begin{gather}
\boldsymbol{A}^T 
\begin{bmatrix} 0 & -x \\ x & 0 \end{bmatrix}\\
-\boldsymbol{A} = \begin{bmatrix} 0 & -x \\ x & 0 \end{bmatrix}\\
-\boldsymbol{A} =\boldsymbol{A}^T 
\end{gather}
\item \emph{Explain why the diagonal entries of a skew-symmetric matrix must be zero.}
\\\textbf{Answer: } The following is true of a transpose:
\begin{equation}
diag(A) = diag(A^T)
\end{equation}
That is because the diagonal doesn't change on a transpose. We also know the following is true of skew-symmetric matrices:
\begin{equation}
A^T = -A
\end{equation}
In order for both of the equations to be true the diagonal has to be 0 of a skew-symmetric matrix. Otherwise when we negate the matrix, A, the diagonal changes and the equality $A^{T} = -A$ is no longer true.
\item \emph{ Show that for a skew-symmetric matrix A, and any n-vector x, (Ax) perpendicular x. This means that Ax and x are orthogonal. Hint. First show that for any n x n matrix A and n-vector x, x T(Ax) = SUM(n i,j=1 Aijxixj ).}
\\\textbf{Answer: } Okay first off, the multiplication of $\boldsymbol{A}\bm{x}$ creates a column vector where the individual items are defined by a given row of matrix A multiplied by the single column vector, x. So a resulting item may look like $a_{11}x{1} + a{12}x{2} + ... + a{1n}x{n}$. And the resulting column vector is also size [n x 1]. When this is multiplied by $x^T$ the dimensionality of the vector multiplication results in a single value. However, it really is just multiplying the individual elements of $\boldsymbol{A}\bm{x}$ by the elements of $\bm{x}^T$ and then summing them. In otherwords:
\begin{gather}
\begin{bmatrix}
x_1 & x_2 & ... & x_n
\end{bmatrix} 
\begin{bmatrix}
a_{11} & a_{12} & ... & a_{1n} \\
a_{21} & a_{22} & ... & ... \\
... & ... & ... & ...\\
a_{n1} & ... & ... & a_{nn} \end{bmatrix}
\begin{bmatrix}
x_1 \\
x_2 \\
...\\
x_n \end{bmatrix}\\
=
x_1(a_{11}x_1 + a_{12}x_2 + ... + a_{1n}x_n) +\\
 x_2(a_{21}x_1 + a_{22}x_2 + ... + a_{2n}x_n) +\\
 ... + x_n(a_{n1}x_1 + a_{n2}x_2 + ... + a_{nn}x_n)
= \sum_{i,j = 1}^{n}A_{ij}x_ix_j
\end{gather}
Now in a skew symmetric matrix all the diagonal entries of the matrix are 0. So in the above that drops out anywhere within $\boldsymbol{A}$ where i = j. Furthermore for 
$A^{T} = -A$ to be true then
 $a_{ij} = -a_{ji}$ other than the diagonal entries. So when we sum up all the elements there will be a sort of complement for each off-diagonal entry. For example take the first off-diagonal entries,
 $a_{12}x_2x_1$ and
 $a_{21}x_1x_2$. Since
 $a_{12} = -a_{21}$ when we substitute in for
 $a_{21}$ into the summation we see: 
\begin{equation}
a_{12}x_2x_1 + a_{21}x_1x_2 = a_{12}x_2x_1 - a_{12}x_1x_2 = 0
\end{equation}
If we were to continue the summation for all of A, we would see that the total of the summation comes to 0. Since the definition of orthogonality is given by $a'b = 0$ and $\bm{x}^T\boldsymbol{A}\bm{x}$ = 0, then $\bm{x}^T$ must be orthogonal to $\boldsymbol{A}\bm{x}$.
\\\\\\\\\\\\
\item \emph{Now suppose A is any matrix for which (Ax) perp x for any n-vector x. Show that A
must be skew-symmetric. }
\\\textbf{Answer: } So using the formulas below:
\begin{equation}
(e_i + e_j)^TA(e_i + e_j) = A_{ii} + A_{jj} + A_{ij} + A_{ji} \\
e_i^TAe_i = A_{ii}
\end{equation}
If we say A is orthogonal to all $e_i$ and $e_j$ then we can say the following:
\begin{equation}
e_i^TAe_i = A_{ii} = 0 \\
e_j^TAe_j = A_{jj} = 0
\end{equation}
Then the equation turns into:
\begin{equation}
(e_i + e_j)^TA(e_i + e_j) = A_{ii} + A_{jj} + A_{ij} + A_{ji} = 0 \\
\end{equation}
Now I'll stop because this was due by 3:59 pM!


\begin{equation}
(e_i + e_j)^TA(e_i + e_j) =  A_{ij} + A_{ji}
\end{equation}
Now again we're looking for an orthogonal condition so we want $(e_i + e_j)^TA(e_i + e_j)$ to be equal to zero. Thus $A_{ij} = -A{ji}$ proving skew symmetric. We apply the generalization by saying that x can equal $e_i + e_j$ and thus A is a skew symmetric matrix.
\end{enumerate}
\item 
\begin{gather}
A =
\begin{bmatrix}
1 & 3 & 2 \\
2 & 0 & -1
\end{bmatrix}
B = 
\begin{bmatrix}
1 & 2\\
0 & 1 \\
1 & 0
\end{bmatrix}
C = 
\begin{bmatrix}
2 & 1 & 1 \\
5 & -6 & -4 \\
\end{bmatrix}
\end{gather}
Now find AB and CB
\begin{gather}
AB= 
\begin{bmatrix}
3 & 5\\
1 & 2
\end{bmatrix}
CB = 
\begin{bmatrix}
3 & 5 \\
1 & 4
\end{bmatrix}
\end{gather}
In answer to the second part of the question. Yes B is singular.
\item \emph{Determinant computation:}
\begin{gather}
A=
\begin{vmatrix}
2 & 0\\
0 & 3
\end{vmatrix}
= 6 \\ B = 
\begin{vmatrix}
2 & 1\\
0 & 3
\end{vmatrix}
= 6 \\ C = 
\begin{vmatrix}
1 & 2\\
3 & 6
\end{vmatrix}
= 0 \\ D =
\begin{vmatrix}
1 & 2\\
3 & 4
\end{vmatrix}
= -2 \\ E = 
\begin{vmatrix}
3 & -7 \\
2 & 1
\end{vmatrix}
= 17 \\ E^T =
\begin{vmatrix}
3 & 2 \\
-7 & 1
\end{vmatrix}
= 17 \\ F = 
\begin{vmatrix}
3 & 2 \\
1 & 4
\end{vmatrix}
=10 \\F^{-1} =
\begin{vmatrix}
.4 & -.2\\
-.1 &.3
\end{vmatrix}
= .1
\end{gather}
\item \emph{What lower triangular matrix E puts A into upper triangular form EA = U.} \\
\textbf{Answer: } If A is the following:
\begin{gather}
\begin{bmatrix}
2 & 1 & 0 \\
0 & 4 & 2\\
6 & 3 & 5
\end{bmatrix}
\end{gather}
Then the lower triangular matrix E that turns A into an upper triangular matrix is:
\begin{gather}
E =
\begin{bmatrix}
1 & 0 & 0\\
0 & 1 & 0\\
-3 & 0 & 1
\end{bmatrix}
\end{gather}
And EA is the following
\begin{gather}
EA =
\begin{bmatrix}
2 & 1 & 0\\
0 & 4 & 2\\
0 & 0 & 5
\end{bmatrix}
\end{gather}
\end{enumerate}
\end{document}





